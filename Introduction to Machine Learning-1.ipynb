{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4431866",
   "metadata": {},
   "source": [
    "Artificial Intelligence----It is the science and engineering of making intelligent machines, especially intelligent computer programs. It is related to the similar task of using computers to understand human intelligence \n",
    "Example --Examples of AI applications include: Googleâ€™s AI-Powered Predictions, Ridesharing Apps Like Uber and Lyft, Commercial Flights Use an AI Autopilot, etc.\n",
    "\n",
    "\n",
    "\n",
    "Machine Learning ___Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.\n",
    "Examples of ML applications include: Virtual Personal Assistants: Siri, Alexa, Google, etc., Email Spam and Malware Filtering.\n",
    "\n",
    "\n",
    "\n",
    "Deep Learning___Deep learning is part of a broader family of machine learning methods, which is based on artificial neural networks with representation learning\n",
    "Examples of DL applications include: Sentiment based news aggregation, Image analysis and caption generation, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f207fbf",
   "metadata": {},
   "source": [
    "Question -2 \n",
    "\n",
    "Supervised learning, also known as supervised machine learning, is a subcategory of machine learning and artificial intelligence. It is defined by its use of labeled datasets to train algorithms that to classify data or predict outcomes accurately. As input data is fed into the model, it adjusts its weights until the model has been fitted appropriately, which occurs as part of the cross validation process. Supervised learning helps organizations solve for a variety of real-world problems at scale, such as classifying spam in a separate folder from your inbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb26627",
   "metadata": {},
   "source": [
    "Question-3 Unsupervised learning is the training of a machine using information that is neither classified nor labeled and allowing the algorithm to act on that information without guidance. Here the task of the machine is to group unsorted information according to similarities, patterns, and differences without any prior training of data. \n",
    "\n",
    "Unlike supervised learning, no teacher is provided that means no training will be given to the machine. Therefore the machine is restricted to find the hidden structure in unlabeled data by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc56ab",
   "metadata": {},
   "source": [
    "question -4\n",
    "\n",
    "AI is a computer algorithm which exhibits intelligence through decision making.\n",
    "\n",
    "ML is an AI algorithm which allows system to learn from data.\n",
    "DL is a ML algorithm that uses deep(more than one layer) neural networks to analyze data and provide output accordingly\n",
    "\n",
    "\n",
    "Data science combines math and statistics, specialized programming, advanced analytics, artificial intelligence (AI), and machine learning with specific subject matter expertise to uncover actionable insights hidden in an organization's data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df6da8",
   "metadata": {},
   "source": [
    "Question-4\n",
    "\n",
    "\n",
    "The main difference between these types is the level of availability of ground truth data, which is prior knowledge of what the output of the model should be for a given input.\n",
    "\n",
    "Supervised learning aims to learn a function that, given a sample of data and desired outputs, approximates a function that maps inputs to outputs.\n",
    "\n",
    "Semi-supervised learning aims to label unlabeled data points using knowledge learned from a small number of labeled data points.\n",
    "\n",
    "Unsupervised learning does not have (or need) any labeled outputs, so its goal is to infer the natural structure present within a set of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a35c7",
   "metadata": {},
   "source": [
    "Question -6\n",
    "The train-test split procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model.\n",
    "\n",
    "The procedure involves taking a dataset and dividing it into two subsets. The first subset is used to fit the model and is referred to as the training dataset. The second subset is not used to train the model; instead, the input element of the dataset is provided to the model, then predictions are made and compared to the expected values. This second dataset is referred to as the test dataset.\n",
    "\n",
    "Train Dataset: Used to fit the machine learning model.\n",
    "Test Dataset: Used to evaluate the fit machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d61ef3c",
   "metadata": {},
   "source": [
    "Question \n",
    "\n",
    "Unsupervised learning is commonly used in anomaly detection to identify unusual or unexpected patterns in data without requiring labeled examples of anomalies during training.\n",
    "\n",
    "Anomaly Detection: Once the model of the normal data distribution is established, it can be used to detect anomalies in new, unseen data points. Anomalies are identified based on their deviation from the learned normal pattern. The specific method for anomaly detection depends on the algorithm used:\n",
    "\n",
    "In clustering algorithms, anomalies are points that do not belong to any cluster or are in small, isolated clusters.\n",
    "Autoencoders identify anomalies based on high reconstruction errors.\n",
    "Isolation Forest detects anomalies based on the number of splits required to isolate a data point.\n",
    "One-Class SVM identifies anomalies based on their position relative to the learned hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe2142",
   "metadata": {},
   "source": [
    "Supervised Anomaly Detection Algorithms:\n",
    "\n",
    "Isolation Forest: Although primarily used in an unsupervised manner, the Isolation Forest algorithm can also be adapted to a semi-supervised setting by utilizing some labeled data for training.\n",
    "\n",
    "Support Vector Machines (SVM): SVMs can be used for both classification and anomaly detection. In the context of anomaly detection, they are often employed in a one-class setting, where the algorithm learns a decision boundary around normal data.\n",
    "\n",
    "k-Nearest Neighbors (k-NN): k-NN can be used in a supervised manner for anomaly detection by training on labeled data to distinguish between normal and anomalous instances.\n",
    "\n",
    "Random Forest and Decision Trees: These algorithms can be used to classify instances as normal or anomalous based on features. They can also be employed as part of an ensemble approach for anomaly detection.\n",
    "\n",
    "Unsupervised Anomaly Detection Algorithms:\n",
    "\n",
    "k-Means Clustering: Anomalies can be identified as data points that do not belong to any cluster or form small clusters.\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise): DBSCAN is effective at identifying outliers in dense regions of data.\n",
    "\n",
    "Autoencoders: Neural network architectures that learn to encode and decode data can be used to identify anomalies based on reconstruction errors.\n",
    "\n",
    "Principal Component Analysis (PCA): PCA can be used to reduce the dimensionality of data and anomalies can be identified based on their distance from the principal components.\n",
    "\n",
    "Isolation Forest: This algorithm randomly isolates instances using decision trees and identifies anomalies based on the number of splits required.\n",
    "\n",
    "Local Outlier Factor (LOF): LOF measures the local density deviation of a data point with respect to its neighbors and can identify regions with lower density as anomalies.\n",
    "\n",
    "One-Class SVM (Support Vector Machine): One-Class SVM learns a hyperplane that separates normal data from everything else.\n",
    "\n",
    "Histogram-Based Methods: These methods create histograms of feature values and identify anomalies based on deviations from the expected histogram.\n",
    "\n",
    "Statistical Methods: Techniques like Z-Score, Modified Z-Score, and Tukey's Fences can identify anomalies based on statistical measures.\n",
    "\n",
    "Mahalanobis Distance: Measures the distance between a data point and the center of a distribution, identifying anomalies that are far from the distribution's center.\n",
    "\n",
    "Gaussian Mixture Models (GMM): GMMs can be used to model the data distribution and anomalies are identified based on low likelihood scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e5213b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
